1
00:00:00,370 --> 00:00:04,440
You implemented the sigma
point generation in C++.

2
00:00:04,440 --> 00:00:07,280
That's very good,
because it's great preparation for

3
00:00:07,280 --> 00:00:10,130
the project at the end of this module.

4
00:00:10,130 --> 00:00:13,880
Now you know how to represent
the uncertainty of the posterior state

5
00:00:13,880 --> 00:00:16,180
estimation with sigma points.

6
00:00:16,180 --> 00:00:19,530
And we can put the sigma points
into the process function.

7
00:00:19,530 --> 00:00:20,950
But wait a second.

8
00:00:20,950 --> 00:00:25,130
The process function also considers
the process noise vector, mu k.

9
00:00:25,130 --> 00:00:29,170
And this also has a non-linear effect.

10
00:00:29,170 --> 00:00:33,330
Fortunately, the UKF
provides a super-easy way

11
00:00:33,330 --> 00:00:37,030
to handle non-linear
process noise effects.

12
00:00:37,030 --> 00:00:39,259
And this is what I want to
show you in this video.

13
00:00:40,480 --> 00:00:43,020
Let's look into this
process noise again.

14
00:00:43,020 --> 00:00:46,010
This is the complete process model.

15
00:00:46,010 --> 00:00:49,840
Considering the process noise vector,
looking at this,

16
00:00:49,840 --> 00:00:52,270
some of you might think, wait a second.

17
00:00:52,270 --> 00:00:58,060
Didn't we say this type of vector
is the process vector nu K?

18
00:00:58,060 --> 00:01:01,130
Yes, you are absolutely right.

19
00:01:01,130 --> 00:01:06,486
In the last lesson about the Kalman
filter, this was what we called nu K.

20
00:01:06,486 --> 00:01:11,481
And that made a big difference because
you had to calculate this big process

21
00:01:11,481 --> 00:01:13,400
noise covariance matrix Q.

22
00:01:13,400 --> 00:01:18,118
The thing is if look into literature and
you find this process noise vector,

23
00:01:18,118 --> 00:01:21,887
nu K, you really have to be
careful of what the authors mean.

24
00:01:21,887 --> 00:01:24,250
Sometimes they mean this vector.

25
00:01:24,250 --> 00:01:29,181
Each row of this vector tells
the influence of the process

26
00:01:29,181 --> 00:01:33,403
noise on a specific state between K and
K plus 1.

27
00:01:33,403 --> 00:01:38,790
So it has the same dimension as the
state vector, and it depends on delta t.

28
00:01:38,790 --> 00:01:43,860
Mostly this is the case when you read
about the standard linear Kalman filter,

29
00:01:43,860 --> 00:01:46,590
but sometimes the authors
mean this vector.

30
00:01:46,590 --> 00:01:48,080
This is something much simpler,

31
00:01:48,080 --> 00:01:52,980
because this vector just lists the
individual independent noise processes.

32
00:01:52,980 --> 00:01:56,940
This vector doesn't say anything about
the effect of these noise processes on

33
00:01:56,940 --> 00:02:00,990
the state vector, and
it does not depend on delta t.

34
00:02:00,990 --> 00:02:03,981
Usually this is what authors mean
when they write about the unscented

35
00:02:03,981 --> 00:02:05,540
Kalman filter.

36
00:02:05,540 --> 00:02:10,139
This issue confuses me a lot when I
started getting into Kalman filters.

37
00:02:10,139 --> 00:02:12,840
So in this lesson about
the UKF when I mention nu K,

38
00:02:12,840 --> 00:02:16,370
I'm always talking about
this process noise vector.

39
00:02:16,370 --> 00:02:19,280
And this is a good thing
because the covariance matrix Q

40
00:02:19,280 --> 00:02:22,299
of this process noise is
much simpler in this case.

41
00:02:23,500 --> 00:02:27,210
To write down this matrix, you just need
to know the stochastic properties of

42
00:02:27,210 --> 00:02:30,720
these noise processes,
which we already defined.

43
00:02:30,720 --> 00:02:33,450
Then Q is given by this matrix.

44
00:02:33,450 --> 00:02:36,440
This matrix contains the variances
of the noise processes.

45
00:02:37,450 --> 00:02:42,230
The covariances here are zero because
the longitudinal acceleration noise and

46
00:02:42,230 --> 00:02:45,760
the yaw acceleration noise
are considered independent.

47
00:02:45,760 --> 00:02:49,580
Now we clarified what this
process noise vector is and

48
00:02:49,580 --> 00:02:52,620
what its covariance matrix Q looks like.

49
00:02:52,620 --> 00:02:56,477
What I want to show you now is how
you can represent the uncertainty of

50
00:02:56,477 --> 00:02:59,570
the covariance matrix
Q with sigma points.

51
00:02:59,570 --> 00:03:02,130
The solution is called augmentation.

52
00:03:02,130 --> 00:03:07,310
This is an overview on how we generated
signal points without considering Q.

53
00:03:07,310 --> 00:03:10,690
What we will do now is
build the augmented state,

54
00:03:10,690 --> 00:03:13,900
where we add the noise
vector to the state vector.

55
00:03:13,900 --> 00:03:16,600
I call this state Xa.

56
00:03:16,600 --> 00:03:19,800
The augmented state
dimension in our case is 7.

57
00:03:19,800 --> 00:03:23,580
This also means we need
15 sigma points now.

58
00:03:23,580 --> 00:03:26,360
The additional four sigma
points will be representing

59
00:03:26,360 --> 00:03:29,600
the uncertainty caused
by the process noise.

60
00:03:29,600 --> 00:03:33,600
We also build the augmented
covariance matrix Pa.

61
00:03:33,600 --> 00:03:37,440
This matrix has 7 rows and 7 columns.

62
00:03:37,440 --> 00:03:42,430
You just add the matrix Q
as a lower right block, and

63
00:03:42,430 --> 00:03:45,290
fill up the remaining fields with a 0.

64
00:03:45,290 --> 00:03:48,710
Finally, the way to generate
the 15 sigma points

65
00:03:48,710 --> 00:03:51,030
is exactly the same as before.

66
00:03:51,030 --> 00:03:54,230
Just use the augmented
elements as input.

67
00:03:54,230 --> 00:03:58,680
In the next quiz, you will adapt
your sigma point generation function

68
00:03:58,680 --> 00:03:59,890
to the augmented state.
